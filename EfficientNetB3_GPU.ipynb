{"cells":[{"cell_type":"markdown","metadata":{},"source":["# <center> Rozpoznawanie monet - projekt\n","### <center> EfficientNetB3"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"import\"></a>\n","## Import modułów i konfiguracja"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-11T15:05:12.583560Z","iopub.status.busy":"2022-05-11T15:05:12.582455Z","iopub.status.idle":"2022-05-11T15:05:18.852011Z","shell.execute_reply":"2022-05-11T15:05:18.851248Z","shell.execute_reply.started":"2022-05-11T15:05:12.583428Z"},"trusted":true},"outputs":[],"source":["# basic utils\n","import numpy as np\n","import pandas as pd\n","import os\n","import time\n","import shutil\n","\n","# data representation\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# neural network\n","from sklearn.metrics import confusion_matrix, classification_report\n","import tensorflow as tf\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.layers import Dense, Dropout, BatchNormalization\n","from keras.optimizers import Adamax\n","from keras.models import Model\n","\n","# config\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","sns.set_style('darkgrid')\n","\n","# logger only for getting rid of the warning\n","import logging\n","logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n","import warnings\n","pd.options.display.max_columns = None\n","pd.options.display.max_rows = 90 # visual aid\n","warnings.simplefilter(\"ignore\")\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"makedf\"></a>\n","## Import i obsługa danych\n","załadowanie zbioru danych, preprocessing i wczytanie klas\n","\n","zbiór danych [WorldCoins (kaggle)](https://www.kaggle.com/datasets/wanderdust/coin-images)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-11T15:05:18.865993Z","iopub.status.busy":"2022-05-11T15:05:18.865752Z","iopub.status.idle":"2022-05-11T15:05:21.746832Z","shell.execute_reply":"2022-05-11T15:05:21.746061Z","shell.execute_reply.started":"2022-05-11T15:05:18.865960Z"},"trusted":true},"outputs":[],"source":["sdir=r'\\dataset\\coins\\data'\n","classes=[]\n","datasets=os.listdir(sdir)\n","for d in datasets:\n","    dpath=os.path.join(sdir,d)    \n","    if os.path.isdir(dpath):\n","        print ('processing the ', d, ' dataset')\n","        filepaths = []\n","        labels=[]        \n","        classlist=os.listdir(dpath)\n","        for klass in classlist:            \n","            classpath=os.path.join(dpath, klass)\n","            flist=os.listdir(classpath)\n","            for f in flist:\n","                fpath=os.path.join(classpath,f)\n","                fclass=fpath.split('__')[1].split('.')[0]                \n","                filepaths.append(fpath)\n","                labels.append(fclass)\n","        Fseries=pd.Series(filepaths, name='filepaths')\n","        Lseries=pd.Series(labels, name='labels')        \n","        if d == 'train':\n","            train_df=pd.concat([Fseries, Lseries], axis=1)\n","        elif d == 'test':\n","            test_df=pd.concat([Fseries, Lseries], axis=1)\n","        else:\n","            valid_df= pd.concat([Fseries, Lseries], axis=1)\n","print('train_df lenght: ', len(train_df), '  test_df length: ', len(test_df), '  valid_df length: ', len(valid_df))\n","\n","# train_df class characterization\n","classes=list(train_df['labels'].unique())\n","class_count = len(classes)\n","print('The number of classes in the dataset is: ', class_count)\n","groups=train_df.groupby('labels')\n","print('{0:^30s} {1:^13s}'.format('CLASS', 'IMAGE COUNT'))\n","countlist=[]\n","classlist=[]\n","for label in train_df['labels'].unique():\n","    group=groups.get_group(label)\n","    countlist.append(len(group))\n","    classlist.append(label)\n","    print('{0:^30s} {1:^13s}'.format(label, str(len(group))))\n","\n","# metrics for later dataset balancing\n","\n","# min/max values for numbers of samples\n","max_value=np.max(countlist)\n","max_index=countlist.index(max_value)\n","max_class=classlist[max_index]\n","min_value=np.min(countlist)\n","min_index=countlist.index(min_value)\n","min_class=classlist[min_index]\n","print(max_class, ' has the most images= ',max_value, ' ', min_class, ' has the least images= ', min_value)\n","\n","\n","# average dimensions\n","ht=0\n","wt=0\n","# select 100 random samples of train_df\n","train_df_sample=train_df.sample(n=100, random_state=123,axis=0)\n","for i in range (len(train_df_sample)):\n","    fpath=train_df_sample['filepaths'].iloc[i]\n","    img=plt.imread(fpath)\n","    shape=img.shape\n","    ht += shape[0]\n","    wt += shape[1]\n","print('average height= ', ht//100, ' average width= ', wt//100, 'aspect ratio= ', ht/wt)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"balance\"></a>\n","## balansowanie datasetu\n","rozszerzanie datasetu przez utworzenie lustrzanych i odwróconych obrazów"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-11T15:05:21.749469Z","iopub.status.busy":"2022-05-11T15:05:21.749017Z","iopub.status.idle":"2022-05-11T15:08:45.001744Z","shell.execute_reply":"2022-05-11T15:08:44.997516Z","shell.execute_reply.started":"2022-05-11T15:05:21.749426Z"},"trusted":true},"outputs":[],"source":["def balance(df, n, working_dir, img_size):\n","    def augment(df,n, working_dir, img_size):\n","        aug_dir=os.path.join(working_dir, 'aug')\n","        os.mkdir(aug_dir)        \n","        for label in df['labels'].unique():    \n","            dir_path=os.path.join(aug_dir,label)    \n","            os.mkdir(dir_path)\n","        # create and store the augmented images  \n","        total=0\n","        gen=ImageDataGenerator(horizontal_flip=True,  rotation_range=20, width_shift_range=.2,\n","                                      height_shift_range=.2, zoom_range=.2)\n","        groups=df.groupby('labels') # group by class\n","        for label in df['labels'].unique():  # for every class               \n","            group=groups.get_group(label)  # a dataframe holding only rows with the specified label \n","            sample_count=len(group)   # determine how many samples there are in this class  \n","            if sample_count< n: # if the class has less than target number of images\n","                aug_img_count=0\n","                delta=n - sample_count  # number of augmented images to create\n","                target_dir=os.path.join(aug_dir, label)  # define where to write the images\n","                msg='{0:40s} for class {1:^30s} creating {2:^5s} augmented images'.format(' ', label, str(delta))\n","                print(msg, '\\r', end='') # prints over on the same line\n","                aug_gen=gen.flow_from_dataframe( group,  x_col='filepaths', y_col=None, target_size=img_size,\n","                                                class_mode=None, batch_size=1, shuffle=False, \n","                                                save_to_dir=target_dir, save_prefix='aug-', color_mode='rgb',\n","                                                save_format='jpg')\n","                while aug_img_count<delta:\n","                    images=next(aug_gen)            \n","                    aug_img_count += len(images)\n","                total +=aug_img_count\n","        print('Total Augmented images created= ', total)\n","        # create aug_df and merge with train_df to create composite training set ndf\n","        aug_fpaths=[]\n","        aug_labels=[]\n","        classlist=os.listdir(aug_dir)\n","        for klass in classlist:\n","            classpath=os.path.join(aug_dir, klass)     \n","            flist=os.listdir(classpath)    \n","            for f in flist:        \n","                fpath=os.path.join(classpath,f)         \n","                aug_fpaths.append(fpath)\n","                aug_labels.append(klass)\n","        Fseries=pd.Series(aug_fpaths, name='filepaths')\n","        Lseries=pd.Series(aug_labels, name='labels')\n","        aug_df=pd.concat([Fseries, Lseries], axis=1)        \n","        df=pd.concat([df,aug_df], axis=0).reset_index(drop=True)\n","        return df \n","    \n","    df=df.copy() \n","    # make directories to store augmented images\n","    aug_dir=os.path.join(working_dir, 'aug')    \n","    if 'aug' in os.listdir(working_dir):\n","        print(' Augmented images already exist. To delete these and create new images enter D, else enter U to use these images', flush=True)\n","        ans=input(' ')\n","        if ans == 'D' or ans == 'd':            \n","            shutil.rmtree(aug_dir) # start with an clean empty directory  \n","            augment(df,n, working_dir, img_size)\n","            return df\n","        else:\n","            \n","            return df\n","    else:\n","        augment(df,n, working_dir, img_size)\n","        return df\n","        \n","   \n","n=120 # number of samples in each class\n","working_dir=r'./' # directory to store augmented images\n","img_size=(150,150) # size of augmented images\n","train_df=balance(train_df, n, working_dir, img_size)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"generators\"></a>\n","## Generacja zbiorów danych\n","ostateczne wytworzenie `train_gen`, `test_gen`, `final_test_gen` i `valid_gen`\n","\n","**UWAGA:** dla zbioru testowego `batch_size * test_steps = sample_count` aby uniknąć uczenia się na próbce więcej niż raz"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-11T15:08:45.003633Z","iopub.status.busy":"2022-05-11T15:08:45.003343Z","iopub.status.idle":"2022-05-11T15:08:48.313781Z","shell.execute_reply":"2022-05-11T15:08:48.313052Z","shell.execute_reply.started":"2022-05-11T15:08:45.003595Z"},"trusted":true},"outputs":[],"source":["batch_size=30\n","trgen=ImageDataGenerator(horizontal_flip=True,rotation_range=20, width_shift_range=.2,\n","                                  height_shift_range=.2, zoom_range=.2 )\n","t_and_v_gen=ImageDataGenerator()\n","\n","# training\n","msg='{0:70s} for train generator'.format(' ')\n","print(msg, '\\r', end='') # prints over on the same line\n","train_gen=trgen.flow_from_dataframe(train_df, x_col='filepaths', y_col='labels', target_size=img_size,\n","                                   class_mode='categorical', color_mode='rgb', shuffle=True, batch_size=batch_size)\n","\n","# validation\n","msg='{0:70s} for valid generator'.format(' ')\n","print(msg, '\\r', end='') # prints over on the same line\n","valid_gen=t_and_v_gen.flow_from_dataframe(valid_df, x_col='filepaths', y_col='labels', target_size=img_size,\n","                                   class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=batch_size)\n","\n","# test\n","length=len(test_df)\n","test_batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]  \n","test_steps=int(length/test_batch_size)\n","msg='{0:70s} for test generator'.format(' ')\n","print(msg, '\\r', end='') # prints over on the same line\n","test_gen=t_and_v_gen.flow_from_dataframe(test_df, x_col='filepaths', y_col='labels', target_size=img_size,\n","                                   class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=test_batch_size)\n","\n","# generate report\n","classes=list(train_gen.class_indices.keys())\n","class_indices=list(train_gen.class_indices.values())\n","class_count=len(classes)\n","labels=test_gen.labels\n","print ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps, ' number of classes : ', class_count)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"model\"></a>\n","## Tworzenie modelu\n","tworzenie modelu na podstawie [EfficientNetB3](https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet/EfficientNetB3) z wstępnym przedtrenowaniem. Dodajemy pojedynczą warstwę gęstą 256 neurownów\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-05-11T15:08:51.050435Z","iopub.status.busy":"2022-05-11T15:08:51.050138Z","iopub.status.idle":"2022-05-11T15:08:57.481553Z","shell.execute_reply":"2022-05-11T15:08:57.480820Z","shell.execute_reply.started":"2022-05-11T15:08:51.050376Z"},"trusted":true},"outputs":[],"source":["img_shape=(img_size[0], img_size[1], 3)\n","model_name='EfficientNetB3'\n","base_model=tf.keras.applications.efficientnet.EfficientNetB3(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max') \n","\n","base_model.trainable=True\n","x=base_model.output\n","x=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n","x=Dense(128 ,activation='relu')(x)\n","x=Dropout(rate=.4, seed=123)(x)\n","\n","output=Dense(class_count, activation='softmax')(x)\n","model=Model(inputs=base_model.input, outputs=output)\n","\n","lr=.001 # learning rate\n","model.compile(Adamax(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy']) "]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"train\"></a>\n","# Trening modelu\n","30 epok"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-11T15:08:57.511463Z","iopub.status.busy":"2022-05-11T15:08:57.511082Z","iopub.status.idle":"2022-05-11T15:37:09.231980Z","shell.execute_reply":"2022-05-11T15:37:09.231183Z","shell.execute_reply.started":"2022-05-11T15:08:57.511427Z"},"trusted":true},"outputs":[],"source":["history=model.fit(x=train_gen,  epochs=30, verbose=1,  validation_data=valid_gen,\n","               validation_steps=None,  shuffle=False,  initial_epoch=0)"]},{"cell_type":"markdown","metadata":{},"source":["## Plotowanie statystyk uczenia\n","Loss i Accuracy w relacji kolejnych epok"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def tr_plot(tr_data, start_epoch):\n","    #Plot the training and validation data\n","    tacc=tr_data.history['accuracy']\n","    tloss=tr_data.history['loss']\n","    vacc=tr_data.history['val_accuracy']\n","    vloss=tr_data.history['val_loss']\n","    Epoch_count=len(tacc)+ start_epoch\n","    Epochs=[]\n","    for i in range (start_epoch ,Epoch_count):\n","        Epochs.append(i+1)   \n","    plt.style.use('ggplot')\n","    fontsize=20\n","    fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(20,8))\n","    axes[0].plot (Epochs,tacc,'r',label= 'Accuracy - training', color=\"teal\")\n","    axes[0].plot (Epochs,vacc,'g',label= 'Accuracy - validation', color=\"orange\")\n","    axes[0].set_title('Accuracy metrics', weight='bold', fontsize=fontsize+5)\n","    axes[0].set_xlabel('Epoch', weight='bold', fontsize=fontsize)\n","    axes[0].set_ylabel('Accuracy', weight='bold', fontsize=fontsize)\n","    axes[0].legend()\n","    axes[1].plot(Epochs,tloss, 'r', label='Loss - training', color=\"teal\")\n","    axes[1].plot(Epochs,vloss,'g',label='Loss - validation', color=\"orange\")\n","    axes[1].set_title('Loss metrics', weight='bold', fontsize=fontsize+5)\n","    axes[1].set_xlabel('Epochs', weight='bold', fontsize=fontsize)\n","    axes[1].set_ylabel('Loss', weight='bold', fontsize=fontsize)\n","    axes[1].legend()  \n","    plt.show()\n","    \n","tr_plot(history,0)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"result\"></a>\n","## Wykonanie predykcji wytrenowanym modelem\n","test na batchach danych i funkcje do generowania metryk"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-11T15:38:07.074638Z","iopub.status.busy":"2022-05-11T15:38:07.074403Z","iopub.status.idle":"2022-05-11T15:38:19.151352Z","shell.execute_reply":"2022-05-11T15:38:19.150616Z","shell.execute_reply.started":"2022-05-11T15:38:07.074604Z"},"trusted":true},"outputs":[],"source":["def predictor(test_gen, test_steps):\n","    y_pred= []\n","    y_true=test_gen.labels\n","    classes=list(train_gen.class_indices.keys())\n","    class_count=len(classes)\n","    errors=0\n","    preds=model.predict(test_gen, steps=test_steps, verbose=1) # predict on the test set\n","    tests=len(preds)\n","    for i, p in enumerate(preds):\n","            pred_index=np.argmax(p)         \n","            true_index=test_gen.labels[i]  # labels are integer values\n","            if pred_index != true_index: # a misclassification has occurred                                           \n","                errors=errors + 1\n","            y_pred.append(pred_index)\n","    acc=( 1-errors/tests) * 100\n","    print(f'there were {errors} in {tests} tests for an accuracy of {acc:6.2f}')\n","    ypred=np.array(y_pred)\n","    ytrue=np.array(y_true)\n","    if class_count <=30:\n","        cm = confusion_matrix(ytrue, ypred )\n","        # plot the confusion matrix\n","        plt.figure(figsize=(16, 10))\n","        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n","        plt.xticks(np.arange(class_count)+.5, classes, rotation=90)\n","        plt.yticks(np.arange(class_count)+.5, classes, rotation=0)\n","        plt.xlabel(\"Predicted\")\n","        plt.ylabel(\"Actual\")\n","        plt.title(\"Confusion Matrix\")\n","        plt.show()\n","    clr = classification_report(y_true, y_pred, target_names=classes, digits= 4) # create classification report\n","    print(\"Classification Report:\\n----------------------\\n\", clr)\n","    return errors, tests\n","errors, tests=predictor(test_gen, test_steps)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"save\"></a>\n","## Zapis modelu do pliku"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-11T15:38:19.153334Z","iopub.status.busy":"2022-05-11T15:38:19.152637Z","iopub.status.idle":"2022-05-11T15:38:20.332755Z","shell.execute_reply":"2022-05-11T15:38:20.331273Z","shell.execute_reply.started":"2022-05-11T15:38:19.153293Z"},"trusted":true},"outputs":[],"source":["subject='coins' \n","acc=str(( 1-errors/tests) * 100)\n","index=acc.rfind('.')\n","acc=acc[:index + 3]\n","save_id= subject + '_' + str(acc) + '.h5' \n","model_save_loc=os.path.join(working_dir, save_id)\n","model.save(model_save_loc)\n","print ('model was saved as ' , model_save_loc ) \n","   "]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.15 ('GSN')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"vscode":{"interpreter":{"hash":"d9e377f4398eb9f4b711c45e8cb5dc3e8180c43d8019ae6fa1b089aaae6e4ef9"}}},"nbformat":4,"nbformat_minor":4}
